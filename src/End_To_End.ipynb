{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f58989a5",
   "metadata": {},
   "source": [
    "# ---------------------------\n",
    "# 1. Process PDF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "39e26ea0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Consider using the pymupdf_layout package for a greatly improved page layout analysis.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import pymupdf4llm\n",
    "from langchain_text_splitters import RecursiveCharacterTextSplitter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "53fd24a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "pdf_folder = \"/Users/nguyentoan/Documents/AI_Financial_RAG/Data/SamSung_data\"\n",
    "pdf_files = [f for f in os.listdir(pdf_folder) if f.endswith(\".pdf\")]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "8e0de77b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "S·ªë file PDF: 7\n",
      "['2023_con_quarter04_all.pdf', '2025_3Q_Interim_Report.pdf', '2025_con_quarter03_all.pdf', '2024_con_quarter04_all.pdf', '2023_con_quarter04_note.pdf', '2025_con_quarter03_note.pdf', '2024_con_quarter04_note.pdf']\n"
     ]
    }
   ],
   "source": [
    "print(\"S·ªë file PDF:\", len(pdf_files))\n",
    "print(pdf_files)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "957f280f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ƒêang x·ª≠ l√Ω: 2023_con_quarter04_all.pdf...\n",
      "ƒêang x·ª≠ l√Ω: 2025_3Q_Interim_Report.pdf...\n",
      "ƒêang x·ª≠ l√Ω: 2025_con_quarter03_all.pdf...\n",
      "ƒêang x·ª≠ l√Ω: 2024_con_quarter04_all.pdf...\n",
      "ƒêang x·ª≠ l√Ω: 2023_con_quarter04_note.pdf...\n",
      "ƒêang x·ª≠ l√Ω: 2025_con_quarter03_note.pdf...\n",
      "ƒêang x·ª≠ l√Ω: 2024_con_quarter04_note.pdf...\n",
      "--- Ho√†n th√†nh! T·ªïng c·ªông c√≥ 2681 chunks t·ª´ 7 file. ---\n"
     ]
    }
   ],
   "source": [
    "# Initialize empty lists (Important!)\n",
    "all_chunks = []\n",
    "all_ids = []\n",
    "all_metadatas = []\n",
    "\n",
    "# Initialize text splitter\n",
    "splitter = RecursiveCharacterTextSplitter(\n",
    "    chunk_size=800,\n",
    "    chunk_overlap=150,\n",
    "    separators=[\"\\n##\", \"\\n#\", \"\\n\\n\", \"\\n\", \" \"]\n",
    ")\n",
    "\n",
    "for pdf_file in pdf_files:\n",
    "    pdf_path = os.path.join(pdf_folder, pdf_file)\n",
    "    print(f\"ƒêang x·ª≠ l√Ω: {pdf_file}...\")\n",
    "\n",
    "    # 1. Convert PDF to Markdown\n",
    "    md_text = pymupdf4llm.to_markdown(pdf_path)\n",
    "\n",
    "    # 2. Split text into chunks\n",
    "    chunks = splitter.split_text(md_text)\n",
    "\n",
    "    # 3. Append chunks, metadata, and IDs to the main lists\n",
    "    for i, chunk in enumerate(chunks):\n",
    "        all_chunks.append(chunk)\n",
    "        all_metadatas.append({\"source\": pdf_file, \"chunk_id\": i})\n",
    "        all_ids.append(f\"{pdf_file}_{i}\")\n",
    "\n",
    "print(f\"--- Ho√†n th√†nh! T·ªïng c·ªông c√≥ {len(all_chunks)} chunks t·ª´ {len(pdf_files)} file. ---\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f2055fba",
   "metadata": {},
   "source": [
    "# 2. Initialize ChromaDB\n",
    "# ---------------------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "665e99f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import chromadb\n",
    "from chromadb.config import Settings\n",
    "# Fix: Use chromadb.PersistentClient instead of the deprecated Settings configuration\n",
    "client = chromadb.PersistentClient(path=\"/Users/nguyentoan/Documents/\" \\\n",
    "                                            \"AI_Financial_RAG/Data/chroma_samsung_db\")\n",
    "\n",
    "collection_name = \"samsung_financials\"\n",
    "if collection_name in [c.name for c in client.list_collections()]:\n",
    "    collection = client.get_or_create_collection(collection_name)\n",
    "else:\n",
    "    collection = client.create_collection(collection_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "db7fa790",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import sys\n",
    "\n",
    "# # 1. Force install the specific compatible versions into the current environment\n",
    "# !{sys.executable} -m pip install \"huggingface-hub<1.0.0\" \"sentence-transformers==3.0.1\" \"langchain-huggingface\" --force-reinstall\n",
    "\n",
    "# # 2. Restart the kernel (you must do this manually after the cell finishes!)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "829dc468",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_huggingface import HuggingFaceEmbeddings\n",
    "embed_model = HuggingFaceEmbeddings(model_name=\"sentence-transformers/all-MiniLM-L6-v2\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c0038263",
   "metadata": {},
   "outputs": [],
   "source": [
    "#If the collection already exists ‚Üí delete it to start over.\n",
    "if collection_name in [c.name for c in client.list_collections()]:\n",
    "    client.delete_collection(collection_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c4bb94e2",
   "metadata": {},
   "source": [
    "# Add Files "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc635aef",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ƒê√£ th√™m 2681 chunk PDF v√†o ChromaDB (qua LangChain wrapper)\n"
     ]
    }
   ],
   "source": [
    "from langchain_chroma import Chroma\n",
    "#  Chroma wrapper\n",
    "vectorstore = Chroma(\n",
    "    client=client,                     \n",
    "    collection_name= collection_name,\n",
    "    embedding_function=embed_model\n",
    ")\n",
    "# Sync 3 list: chunks, metadatas, ids\n",
    "if len(all_metadatas) != len(all_chunks):\n",
    "    all_metadatas = [{\"source\": \"PDF_file\"} for _ in all_chunks]\n",
    "\n",
    "# Generate unique IDs for each chunk (if not already generated)\n",
    "all_ids = [f\"chunk_{i}\" for i in range(len(all_chunks))]\n",
    "\n",
    "#   Add texts to ChromaDB with metadata and IDs\n",
    "vectorstore.add_texts(\n",
    "    texts=all_chunks,\n",
    "    metadatas=all_metadatas,\n",
    "    ids=all_ids\n",
    ")\n",
    "\n",
    "print(f\"ƒê√£ th√™m {len(all_chunks)} chunk PDF v√†o ChromaDB (qua LangChain wrapper)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "087586fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import sys\n",
    "# !{sys.executable} -m pip install langchain-chroma"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "badce4f6",
   "metadata": {},
   "source": [
    "# Add File Json "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "id": "60919501",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Added 60 events into ChromaDB (chunk collection)\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "\n",
    "with open(\"/Users/nguyentoan/Documents/AI_Financial_RAG/Data/samsung_special_events.json\", \"r\") as f:\n",
    "    events = json.load(f)\n",
    "\n",
    "event_docs = []\n",
    "event_metadatas = []\n",
    "event_ids = []\n",
    "\n",
    "for i, e in enumerate(events):\n",
    "    event_date = e['Date'].split(\"T\")[0]\n",
    "\n",
    "    text = (\n",
    "        f\"Date: {event_date}. \"\n",
    "        f\"Open: {e['Open']:.2f}, High: {e['High']:.2f}, \"\n",
    "        f\"Low: {e['Low']:.2f}, Close: {e['Close']:.2f}, \"\n",
    "        f\"Volume: {e['Volume']}.\"\n",
    "    )\n",
    "\n",
    "    event_docs.append(text)\n",
    "    event_metadatas.append({\n",
    "        \"source\": \"samsung_special_events.json\",\n",
    "        \"type\": \"event\",\n",
    "        \"date\": event_date\n",
    "    })\n",
    "    event_ids.append(f\"event_{i}\")\n",
    "\n",
    "# üî• ADD QUA LANGCHAIN WRAPPER\n",
    "vectorstore.add_texts(\n",
    "    texts=event_docs,\n",
    "    metadatas=event_metadatas,\n",
    "    ids=event_ids\n",
    ")\n",
    "\n",
    "print(f\" Added {len(event_docs)} events into ChromaDB (chunk collection)\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "id": "26b91c21",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total daily records: 6530\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "\n",
    "with open(\"/Users/nguyentoan/Documents/AI_Financial_RAG/Data/hist_data_cleaned.json\", \"r\") as f:\n",
    "    hist_data = json.load(f)\n",
    "\n",
    "stock_docs = []\n",
    "stock_metadatas = []\n",
    "stock_ids = []\n",
    "\n",
    "for i, d in enumerate(hist_data):\n",
    "    text = (\n",
    "        f\"Ng√†y {d['Date']}: \"\n",
    "        f\"Gi√° m·ªü c·ª≠a {d['Open']}, \"\n",
    "        f\"Gi√° cao nh·∫•t {d['High']}, \"\n",
    "        f\"Gi√° th·∫•p nh·∫•t {d['Low']}, \"\n",
    "        f\"Gi√° ƒë√≥ng c·ª≠a {d['Close']}, \"\n",
    "        f\"Kh·ªëi l∆∞·ª£ng giao d·ªãch {d['Volume']}\"\n",
    "    )\n",
    "\n",
    "    stock_docs.append(text)\n",
    "    stock_metadatas.append({\n",
    "        \"source\": \"hist_data_cleaned.json\",\n",
    "        \"type\": \"daily_price\",\n",
    "        \"date\": d[\"Date\"]\n",
    "    })\n",
    "    stock_ids.append(f\"stock_{i}\")\n",
    "\n",
    "print(f\"Total daily records: {len(stock_docs)}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "id": "ebb96419",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Added batch 1: 5000 documents\n",
      "‚úÖ Added batch 2: 1530 documents\n"
     ]
    }
   ],
   "source": [
    "BATCH_SIZE = 5000  # < 5461\n",
    "\n",
    "for i in range(0, len(stock_docs), BATCH_SIZE):\n",
    "    batch_texts = stock_docs[i:i + BATCH_SIZE]\n",
    "    batch_metadatas = stock_metadatas[i:i + BATCH_SIZE]\n",
    "    batch_ids = stock_ids[i:i + BATCH_SIZE]\n",
    "\n",
    "    vectorstore.add_texts(\n",
    "        texts=batch_texts,\n",
    "        metadatas=batch_metadatas,\n",
    "        ids=batch_ids\n",
    "    )\n",
    "\n",
    "    print(f\"‚úÖ Added batch {i//BATCH_SIZE + 1}: {len(batch_texts)} documents\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d4db86e8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "T·ªïng s·ªë document trong collection 'samsung_financials': 9271\n"
     ]
    }
   ],
   "source": [
    "# document in collection\n",
    "collection = client.get_or_create_collection(collection_name)\n",
    "num_docs = collection.count()\n",
    "print(f\"T·ªïng s·ªë document trong collection '{collection_name}': {num_docs}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "90c4078d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The vectors have 384 dimensions\n"
     ]
    }
   ],
   "source": [
    "# 2. Get the vector collection from vectorstore\n",
    "# Note: _collection is an internal attribute and may change by version\n",
    "collection = vectorstore._collection\n",
    "\n",
    "# 3. Get 1 embedding from database\n",
    "# include=[\"embeddings\"] to only get the embeddings part, limit=1 to only get 1 vector\n",
    "sample_data = collection.get(limit=1, include=[\"embeddings\"])\n",
    "sample_embedding = sample_data[\"embeddings\"][0]\n",
    "\n",
    "# 4. Check the dimensionality of the embedding\n",
    "dimensions = len(sample_embedding)\n",
    "print(f\"The vectors have {dimensions:,} dimensions\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2076d5cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from dotenv import load_dotenv\n",
    "from langchain_groq import ChatGroq\n",
    "\n",
    "# 1. T·∫£i c√°c bi·∫øn t·ª´ file .env v√†o m√¥i tr∆∞·ªùng\n",
    "load_dotenv()\n",
    "\n",
    "# 2. L·∫•y key t·ª´ m√¥i tr∆∞·ªùng (kh√¥ng bao gi·ªù vi·∫øt tr·ª±c ti·∫øp v√†o code)\n",
    "# Bi·∫øn groq_api_key ph·∫£i tr√πng v·ªõi t√™n b·∫°n ƒë·∫∑t trong file .env\n",
    "api_key = os.getenv(\"groq_api_key\")\n",
    "\n",
    "# 3. Kh·ªüi t·∫°o LLM\n",
    "llm = ChatGroq(\n",
    "    temperature=0, \n",
    "    model_name=\"llama-3.3-70b-versatile\", \n",
    "    groq_api_key=api_key\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a632ed0",
   "metadata": {},
   "outputs": [],
   "source": [
    "#  retriever from vectorstore (Chroma)\n",
    "retriever = vectorstore.as_retriever(search_kwargs={\"k\": 6})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "id": "98d492ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.runnables import RunnableLambda, RunnablePassthrough\n",
    "from langchain_groq import ChatGroq\n",
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "from langchain_core.output_parsers import StrOutputParser\n",
    "\n",
    "# Function to format documents (Ensure docs is a list of Document objects)\n",
    "def format_docs(docs):\n",
    "    return \"\\n\\n\".join(doc.page_content for doc in docs)\n",
    "\n",
    "# Prompt\n",
    "template = \"\"\"You are a professional financial analysis assistant.\n",
    "Based on the provided Context, answer the question in detail.\n",
    "\n",
    "Context:\n",
    "{context}\n",
    "\n",
    "Question: {question}\n",
    "\n",
    "Requirements:\n",
    "- If the information exists in the context, list it completely.\n",
    "- Answer in professional English.\n",
    "- If the information is not available, say 'I could not find specific data for this request.'\n",
    "\n",
    "Answer:\"\"\"\n",
    "\n",
    "prompt = ChatPromptTemplate.from_template(template)\n",
    "\n",
    "# RAG Chain using LCEL (Flexible structure)\n",
    "rag_chain = (\n",
    "    {\n",
    "        # Extract question from input -> pass to retriever -> format retrieved documents\n",
    "        \"context\": (lambda x: x[\"question\"]) | retriever | format_docs_runnable,\n",
    "        \"question\": lambda x: x[\"question\"]\n",
    "    }\n",
    "    | prompt\n",
    "    | llm\n",
    "    | StrOutputParser()\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "id": "c2d81acf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- RESULT ---\n",
      "Based on the provided context, Samsung Electronics Co., Ltd. and its subsidiaries appear to be focusing on developing a wide range of products, including electronic devices, network solutions, software, and TVs. The specific examples of products and services can be found in the \"NOTES TO THE CONSOLIDATED FINANCIAL STATEMENTS\" section, which lists the various subsidiaries and their respective areas of focus.\n",
      "\n",
      "Some specific examples of products and services that Samsung is currently developing include:\n",
      "\n",
      "1. Electronic devices, as mentioned in the context of Samsung Electronics Rus Company LLC (SERC), Samsung Electronics Ukraine Company LLC (SEUC), and Samsung Electronics Central Eurasia LLP (SECE).\n",
      "2. Network solutions, as mentioned in the context of SAMSUNG Zhilabs, S.L.\n",
      "3. Software, as mentioned in the context of Sonio SAS.\n",
      "4. TVs, as mentioned in the context of Samsung Electronics Rus Kaluga LLC (SERK).\n",
      "5. R&D activities, as mentioned in the context of Samsung Nanoradio Design Center (SNDC), Samsung Denmark Research Center ApS (SDRC), Samsung Cambridge Solution Centre Limited (SCSC), FOODIENT LTD., Oxford Semantic Technologies Limited (OST), Samsung R&D Institute Ukraine (SRUKR), and Samsung R&D Institute Rus LLC (SRR).\n",
      "\n",
      "These examples can be found in the \"1. General Information\" section, specifically in the \"1.1 Company Overview\" subsection, which lists the various subsidiaries and their respective areas of focus.\n",
      "\n",
      "The information is found in the following files:\n",
      "\n",
      "- NOTES TO THE CONSOLIDATED FINANCIAL STATEMENTS as of December 31, 2023 and 2022\n",
      "- NOTES TO THE CONSOLIDATED FINANCIAL STATEMENTS as of December 31, 2024 and 2023\n",
      "- NOTES TO THE CONSOLIDATED FINANCIAL STATEMENTS as of September 30, 2025 and December 31, 2024\n",
      "\n",
      "It is worth noting that the context provided does not offer a comprehensive overview of Samsung's entire product portfolio, but rather provides a snapshot of the company's subsidiaries and their respective areas of focus. Therefore, this list may not be exhaustive, and additional information may be available in other files or sources.\n"
     ]
    }
   ],
   "source": [
    "# 7. Test run\n",
    "query = \"What core products is Samsung currently focusing on developing? And provide specific examples, including which file the information is found in.\"\n",
    "\n",
    "try:\n",
    "    response = rag_chain.invoke({\"question\": query})\n",
    "    print(\"--- RESULT ---\")\n",
    "    print(response)\n",
    "\n",
    "except Exception as e:\n",
    "    print(f\"Error while running the chain: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "47415aca",
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "\n",
    "def test_query_performance():\n",
    "    \"\"\"Test query with timing\"\"\"\n",
    "    query = \"What core products is Samsung currently focusing on developing?\"\n",
    "    \n",
    "    start_time = time.time()\n",
    "    \n",
    "    # N·∫øu chain d√πng StrOutputParser() cu·ªëi c√πng, k·∫øt qu·∫£ l√† string\n",
    "    result = rag_chain.invoke({\"question\": query})\n",
    "    \n",
    "    end_time = time.time()\n",
    "    \n",
    "    print(f\"Query processed in {end_time - start_time:.2f} seconds\")\n",
    "    print(\"Answer:\", result)  # result l√† string\n",
    "    \n",
    "    # N·∫øu mu·ªën d√πng source_documents, c·∫ßn chain tr·∫£ v·ªÅ dict\n",
    "    if hasattr(rag_chain, \"source_documents\") and rag_chain.source_documents:\n",
    "        print(f\"Used {len(rag_chain.source_documents)} source documents\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "id": "2d81a0c2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Query processed in 5.11 seconds\n",
      "Answer: Based on the provided context, Samsung Electronics is currently focusing on developing a wide range of electronic devices, including:\n",
      "\n",
      "1. Smartphones: As the smartphone market shows high saturation, Samsung is emphasizing the importance of competitiveness in the overall experience based on software for applications, UX, games, media, digital wallets, AI, security, etc.\n",
      "2. Home appliances: Suzhou Samsung Electronics Co., Ltd. (SSEC) and Samsung Suzhou Electronics Export Co., Ltd. (SSEC-E) are involved in the manufacture of home appliances, with a focus on products such as air conditioning units, as seen in Samsung Electronics Air Conditioner Europe B.V. (SEACE).\n",
      "3. Communication equipment: Tianjin Samsung Telecom Technology Co., Ltd. (TSTC) is engaged in the manufacture of communication equipment, highlighting Samsung's commitment to developing innovative communication solutions.\n",
      "4. TVs: Samsung Electronics Rus Kaluga LLC (SERK) is involved in the manufacture of TVs, indicating that Samsung is continuing to develop and produce high-quality television products.\n",
      "5. Software and R&D: Various Samsung subsidiaries, such as Samsung Nanoradio Design Center (SNDC), Samsung Denmark Research Center ApS (SDRC), Samsung Cambridge Solution Centre Limited (SCSC), FOODIENT LTD., Oxford Semantic Technologies Limited (OST), and Sonio SAS, are focused on research and development, as well as the sale of software and network solutions.\n",
      "\n",
      "These core products and areas of focus demonstrate Samsung's diversified approach to the electronics industry, with a strong emphasis on innovation, research, and development.\n"
     ]
    }
   ],
   "source": [
    "\n",
    "test_query_performance()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1289b3f6",
   "metadata": {},
   "source": [
    "# Ranker"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "075441b4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "===== AFTER RERANK =====\n",
      "\n",
      "Rank 1 | Score: -3.1682\n",
      "Source: 2025_3Q_Interim_Report.pdf\n",
      "Preview: Samsung Nanoradio Design Center (SNDC) R&D 100.0\n",
      "\n",
      "\n",
      "Samsung Denmark Research Center ApS (SDRC) R&D 100.0\n",
      "\n",
      "\n",
      "Samsung Cambridge Solution Centre Limited (SCSC) R&D 100.0\n",
      "\n",
      "\n",
      "SAMSUNG Zhilabs, S.L. Development\n",
      "\n",
      "Rank 2 | Score: -3.4110\n",
      "Source: 2025_con_quarter03_all.pdf\n",
      "Preview: Samsung Electronics Czech and Slovak s.r.o. (SECZ) Sale of electronic devices 100.0\n",
      "\n",
      "Samsung Electronics Baltics SIA (SEB) Sale of electronic devices 100.0\n",
      "\n",
      "Samsung Electronics Greece S.M.S.A (SEGR) S\n",
      "\n",
      "Rank 3 | Score: -3.4110\n",
      "Source: 2025_con_quarter03_note.pdf\n",
      "Preview: Samsung Electronics Czech and Slovak s.r.o. (SECZ) Sale of electronic devices 100.0\n",
      "\n",
      "Samsung Electronics Baltics SIA (SEB) Sale of electronic devices 100.0\n",
      "\n",
      "Samsung Electronics Greece S.M.S.A (SEGR) S\n",
      "\n",
      "Rank 4 | Score: -3.8782\n",
      "Source: 2025_3Q_Interim_Report.pdf\n",
      "Preview: The smartphone industry has grown significantly since 2007. In 2025, the smartphone portion of total HHP sales volume\n",
      "was approximately 86%, and the feature phone portion of the total was approximatel\n",
      "\n",
      "Rank 5 | Score: -6.4733\n",
      "Source: 2025_con_quarter03_all.pdf\n",
      "Preview: Samsung Electronics Hong Kong Co., Ltd. (SEHK) Sale of electronic devices 100.0\n",
      "\n",
      "Samsung Electronics Taiwan Co., Ltd. (SET) Sale of electronic devices 100.0\n",
      "\n",
      "Suzhou Samsung Electronics Co., Ltd. (SSEC\n"
     ]
    }
   ],
   "source": [
    "query = \"What core products is Samsung currently focusing on developing?\"\n",
    "docs = retriever.invoke(query)\n",
    "from sentence_transformers import CrossEncoder\n",
    "\n",
    "# Load reranker model\n",
    "reranker = CrossEncoder(\"cross-encoder/ms-marco-MiniLM-L-6-v2\")\n",
    "pairs = [(query, doc.page_content) for doc in docs]\n",
    "scores = reranker.predict(pairs)\n",
    "doc_scores = list(zip(docs, scores))\n",
    "\n",
    "reranked_docs = sorted(doc_scores, key=lambda x: x[1], reverse=True)\n",
    "\n",
    "print(\"\\n===== AFTER RERANK =====\")\n",
    "for i, (doc, score) in enumerate(reranked_docs[:5]):\n",
    "    print(f\"\\nRank {i+1} | Score: {score:.4f}\")\n",
    "    print(\"Source:\", doc.metadata.get(\"source\"))\n",
    "    print(\"Preview:\", doc.page_content[:200])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69d82ad9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "===== FINAL ANSWER =====\n",
      "Based on the provided list of Samsung's subsidiaries and their activities, it appears that Samsung is currently focusing on developing a wide range of products, including:\n",
      "\n",
      "1. Electronic devices: With multiple subsidiaries such as Samsung Electronics Rus Company LLC, Samsung Electronics Ukraine Company LLC, Samsung Electronics Central Eurasia LLP, Samsung Electronics Czech and Slovak s.r.o., Samsung Electronics Baltics SIA, and Samsung Electronics Greece S.M.S.A, all involved in the sale of electronic devices, it's clear that Samsung is heavily invested in this area.\n",
      "\n",
      "2. R&D: Many subsidiaries, including Samsung Nanoradio Design Center, Samsung Denmark Research Center ApS, Samsung Cambridge Solution Centre Limited, FOODIENT LTD, Oxford Semantic Technologies Limited, and Samsung R&D Institute Ukraine, are focused on research and development, indicating a strong emphasis on innovation and technological advancement.\n",
      "\n",
      "3. Network solutions: SAMSUNG Zhilabs, S.L. is involved in the development and sale of network solutions, suggesting that Samsung is also focusing on developing products related to networking and telecommunications.\n",
      "\n",
      "4. Software: Sonio SAS is involved in the sale of software and R&D, indicating that Samsung is also developing software products.\n",
      "\n",
      "5. Air conditioning products: Samsung Electronics Air Conditioner Europe B.V. is focused on the sale of air conditioning products, showing that Samsung is also involved in the development of home appliances.\n",
      "\n",
      "Overall, Samsung's product focus appears to be quite diverse, with a strong emphasis on electronic devices, R&D, and network solutions, as well as a presence in the software and home appliances markets.\n"
     ]
    }
   ],
   "source": [
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "from langchain_core.output_parsers import StrOutputParser\n",
    "from langchain_groq import ChatGroq\n",
    "\n",
    "# take top 3 after rerank\n",
    "top_docs = [doc for doc, score in reranked_docs[:3]]\n",
    "\n",
    "context = \"\\n\\n\".join([doc.page_content for doc in top_docs])\n",
    "\n",
    "template = \"\"\"You are a professional financial analysis assistant.\n",
    "\n",
    "Context:\n",
    "{context}\n",
    "\n",
    "Question: {question}\n",
    "\n",
    "Answer:\"\"\"\n",
    "\n",
    "prompt = ChatPromptTemplate.from_template(template)\n",
    "\n",
    "llm = ChatGroq(\n",
    "    temperature=0,\n",
    "    model_name=\"llama-3.3-70b-versatile\",\n",
    "    groq_api_key=api_key\n",
    ")\n",
    "\n",
    "chain = prompt | llm | StrOutputParser()\n",
    "\n",
    "answer = chain.invoke({\n",
    "    \"context\": context,\n",
    "    \"question\": query\n",
    "})\n",
    "\n",
    "print(\"\\n===== FINAL ANSWER =====\")\n",
    "print(answer)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e1fba905",
   "metadata": {},
   "source": [
    "# RAGAS Evaluation "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aad8f056",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/p7/t8mf_9w1121ch7f5wkpf02_r0000gn/T/ipykernel_2334/301924879.py:10: DeprecationWarning: Importing Faithfulness from 'ragas.metrics' is deprecated and will be removed in v1.0. Please use 'ragas.metrics.collections' instead. Example: from ragas.metrics.collections import Faithfulness\n",
      "  from ragas.metrics import Faithfulness, AnswerRelevancy, ContextPrecision\n",
      "/var/folders/p7/t8mf_9w1121ch7f5wkpf02_r0000gn/T/ipykernel_2334/301924879.py:10: DeprecationWarning: Importing AnswerRelevancy from 'ragas.metrics' is deprecated and will be removed in v1.0. Please use 'ragas.metrics.collections' instead. Example: from ragas.metrics.collections import AnswerRelevancy\n",
      "  from ragas.metrics import Faithfulness, AnswerRelevancy, ContextPrecision\n",
      "/var/folders/p7/t8mf_9w1121ch7f5wkpf02_r0000gn/T/ipykernel_2334/301924879.py:10: DeprecationWarning: Importing ContextPrecision from 'ragas.metrics' is deprecated and will be removed in v1.0. Please use 'ragas.metrics.collections' instead. Example: from ragas.metrics.collections import ContextPrecision\n",
      "  from ragas.metrics import Faithfulness, AnswerRelevancy, ContextPrecision\n",
      "/var/folders/p7/t8mf_9w1121ch7f5wkpf02_r0000gn/T/ipykernel_2334/301924879.py:26: DeprecationWarning: LangchainLLMWrapper is deprecated and will be removed in a future version. Use llm_factory instead: from openai import OpenAI; from ragas.llms import llm_factory; llm = llm_factory('gpt-4o-mini', client=OpenAI(api_key='...'))\n",
      "  ragas_llm = LangchainLLMWrapper(llm)\n",
      "/var/folders/p7/t8mf_9w1121ch7f5wkpf02_r0000gn/T/ipykernel_2334/301924879.py:27: DeprecationWarning: LangchainEmbeddingsWrapper is deprecated and will be removed in a future version. Use the modern embedding providers instead: embedding_factory('openai', model='text-embedding-3-small', client=openai_client) or from ragas.embeddings import OpenAIEmbeddings, GoogleEmbeddings, HuggingFaceEmbeddings\n",
      "  ragas_emb = LangchainEmbeddingsWrapper(embedding_model)\n",
      "Evaluating:   0%|          | 0/3 [00:00<?, ?it/s]LLM returned 1 generations instead of requested 3. Proceeding with 1 generations.\n",
      "Evaluating: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 3/3 [00:05<00:00,  1.92s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Available columns: ['user_input', 'retrieved_contexts', 'response', 'reference', 'faithfulness', 'answer_relevancy', 'context_precision']\n",
      "   faithfulness  answer_relevancy  context_precision\n",
      "0           1.0          0.586604                1.0\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# RAGAS Evaluation \n",
    "\n",
    "import nest_asyncio\n",
    "import pandas as pd\n",
    "from datasets import Dataset\n",
    "\n",
    "from ragas import evaluate\n",
    "from ragas.metrics import Faithfulness, AnswerRelevancy, ContextPrecision\n",
    "from ragas.llms import LangchainLLMWrapper\n",
    "from ragas.embeddings import LangchainEmbeddingsWrapper\n",
    "\n",
    "# Fix async loop issue in Jupyter\n",
    "nest_asyncio.apply()\n",
    "\n",
    "\n",
    "def build_ragas_wrappers(llm, embedding_model):\n",
    "    \"\"\"\n",
    "    Wrap LangChain models so RAGAS can use them.\n",
    "    \"\"\"\n",
    "    ragas_llm = LangchainLLMWrapper(llm)\n",
    "    ragas_emb = LangchainEmbeddingsWrapper(embedding_model)\n",
    "    return ragas_llm, ragas_emb\n",
    "\n",
    "# Build Metrics\n",
    "\n",
    "def build_metrics(ragas_llm, ragas_emb):\n",
    "    \"\"\"\n",
    "    Initialize evaluation metrics (new class-based API).\n",
    "    \"\"\"\n",
    "    faithfulness = Faithfulness(llm=ragas_llm)\n",
    "    answer_relevancy = AnswerRelevancy(\n",
    "        llm=ragas_llm,\n",
    "        embeddings=ragas_emb\n",
    "    )\n",
    "    context_precision = ContextPrecision(llm=ragas_llm)\n",
    "\n",
    "    return [faithfulness, answer_relevancy, context_precision]\n",
    "\n",
    "# Create Evaluation Dataset\n",
    "\n",
    "def build_dataset(question, contexts, answer, reference):\n",
    "    \"\"\"\n",
    "    contexts MUST be list of list.\n",
    "    \"\"\"\n",
    "    data = {\n",
    "        \"question\": [question],\n",
    "        \"contexts\": [contexts],  # list of list\n",
    "        \"answer\": [answer],\n",
    "        \"reference\": [reference],\n",
    "    }\n",
    "    return Dataset.from_dict(data)\n",
    "# Run Evaluation\n",
    "\n",
    "def run_evaluation(dataset, metrics):\n",
    "    \"\"\"\n",
    "    Run RAGAS evaluation.\n",
    "    \"\"\"\n",
    "    score = evaluate(\n",
    "        dataset=dataset,\n",
    "        metrics=metrics\n",
    "    )\n",
    "    return score.to_pandas()\n",
    "\n",
    "\n",
    "# ---- Build wrappers\n",
    "ragas_llm, ragas_emb = build_ragas_wrappers(llm, embed_model)\n",
    "\n",
    "# ---- Build metrics\n",
    "metrics = build_metrics(ragas_llm, ragas_emb)\n",
    "\n",
    "# ---- Sample test case\n",
    "question = \"Total Revenue for the nine-month period ended September 30, 2024 are ?\"\n",
    "\n",
    "contexts = [\n",
    "    \"For the nine-month period ended September 30, 2024, total revenue was 225,082,634 million KRW.\"\n",
    "]\n",
    "\n",
    "answer = \"The Total Revenue is 225,082,634 million KRW.\"\n",
    "reference = \"225,082,634 million KRW\"\n",
    "\n",
    "# ---- Build dataset\n",
    "dataset = build_dataset(\n",
    "    question=question,\n",
    "    contexts=contexts,\n",
    "    answer=answer,\n",
    "    reference=reference\n",
    ")\n",
    "\n",
    "# ---- Evaluate\n",
    "df_result = run_evaluation(dataset, metrics)\n",
    "\n",
    "print(\"Available columns:\", df_result.columns.tolist())\n",
    "\n",
    "display_cols = [\n",
    "    col for col in [\n",
    "        \"question\",\n",
    "        \"faithfulness\",\n",
    "        \"answer_relevancy\",\n",
    "        \"context_precision\"\n",
    "    ]\n",
    "    if col in df_result.columns\n",
    "]\n",
    "\n",
    "print(df_result[display_cols])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57ff6361",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
